{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wordcloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-69d58eb7332d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m#from textblob import TextBlob\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#%matplotlib inline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mwordcloud\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSTOPWORDS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'wordcloud'"
     ]
    }
   ],
   "source": [
    "# Load Packages\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "%matplotlib inline \n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "## tweets_df = pd.read_csv(\"vaccination_all_tweets.csv\")\n",
    "tweets_df = pd.read_csv(\"vaccination_all_tweets_0303_1130am.csv\")\n",
    "\n",
    "tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the data\n",
    "\n",
    "print(f\"data shape: {tweets_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deal w/ missing data\n",
    "\n",
    "def missing_data(data):\n",
    "    total = data.isnull().sum()\n",
    "    percent = (data.isnull().sum()/data.isnull().count()*100)\n",
    "    tt = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "    types = []\n",
    "    for col in data.columns:\n",
    "        dtype = str(data[col].dtype)\n",
    "        types.append(dtype)\n",
    "    tt['Types'] = types\n",
    "    return(np.transpose(tt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data(tweets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique values\n",
    "\n",
    "def unique_values(data):\n",
    "    total = data.count()\n",
    "    tt = pd.DataFrame(total)\n",
    "    tt.columns = ['Total']\n",
    "    uniques = []\n",
    "    for col in data.columns:\n",
    "        unique = data[col].nunique()\n",
    "        uniques.append(unique)\n",
    "    tt['Uniques'] = uniques\n",
    "    return(np.transpose(tt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values(tweets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequent values\n",
    "\n",
    "def most_frequent_values(data):\n",
    "    total = data.count()\n",
    "    tt = pd.DataFrame(total)\n",
    "    tt.columns = ['Total']\n",
    "    items = []\n",
    "    vals = []\n",
    "    for col in data.columns:\n",
    "        itm = data[col].value_counts().index[0]\n",
    "        val = data[col].value_counts().values[0]\n",
    "        items.append(itm)\n",
    "        vals.append(val)\n",
    "    tt['Most frequent item'] = items\n",
    "    tt['Frequence'] = vals\n",
    "    tt['Percent from total'] = np.round(vals / total * 100, 3)\n",
    "    return(np.transpose(tt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_frequent_values(tweets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the distribution of data\n",
    "\n",
    "def plot_count(feature, title, df, size=1, ordered=True):\n",
    "    f, ax = plt.subplots(1,1, figsize=(4*size,4))\n",
    "    total = float(len(df))\n",
    "    if ordered:\n",
    "        g = sns.countplot(df[feature], order = df[feature].value_counts().index[:20], palette='Set3')\n",
    "    else:\n",
    "        g = sns.countplot(df[feature], palette='Set3')\n",
    "    g.set_title(\"Number and percentage of {}\".format(title))\n",
    "    if(size > 2):\n",
    "        plt.xticks(rotation=90, size=8)\n",
    "    for p in ax.patches:\n",
    "        height = p.get_height()\n",
    "        ax.text(p.get_x()+p.get_width()/2.,\n",
    "                height,\n",
    "                '{:1.2f}%'.format(100*height/total),\n",
    "                ha=\"center\") \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User names\n",
    "\n",
    "plot_count(\"user_name\", \"User name\", tweets_df,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User location\n",
    "\n",
    "plot_count(\"user_location\", \"User location\", tweets_df,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tweet source\n",
    "\n",
    "plot_count(\"source\", \"Source\", tweets_df,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(STOPWORDS)\n",
    "\n",
    "def show_wordcloud(data, title = None):\n",
    "    wordcloud = WordCloud(\n",
    "        background_color='white',\n",
    "        stopwords=stopwords,\n",
    "        max_words=50,\n",
    "        max_font_size=40, \n",
    "        scale=5,\n",
    "        random_state=1\n",
    "    ).generate(str(data))\n",
    "\n",
    "    fig = plt.figure(1, figsize=(10,10))\n",
    "    plt.axis('off')\n",
    "    if title: \n",
    "        fig.suptitle(title, fontsize=20)\n",
    "        fig.subplots_adjust(top=2.3)\n",
    "\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "def show_wordcloud(data, title=\"\"):\n",
    "    text = \" \".join(t for t in data.dropna())\n",
    "    stopwords = set(STOPWORDS)\n",
    "    stopwords.update([\"t\", \"co\", \"https\", \"amp\", \"U\"])\n",
    "    wordcloud = WordCloud(stopwords=stopwords, scale=4, max_font_size=50, max_words=500,background_color=\"black\").generate(text)\n",
    "    fig = plt.figure(1, figsize=(16,16))\n",
    "    plt.axis('off')\n",
    "    fig.suptitle(title, fontsize=20)\n",
    "    fig.subplots_adjust(top=2.3)\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequent word clouds\n",
    "\n",
    "show_wordcloud(tweets_df['text'], title = 'Prevalent words in tweets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prevelant words in tweets - Indian\n",
    "\n",
    "india_df = tweets_df.loc[tweets_df.user_location==\"India\"]\n",
    "show_wordcloud(india_df['text'], title = 'Prevalent words in tweets from India')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prevelant words in tweets - US\n",
    "\n",
    "us_df = tweets_df.loc[tweets_df.user_location==\"United States\"]\n",
    "show_wordcloud(us_df['text'], title = 'Prevalent words in tweets from US')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prevelant words in tweets - UK\n",
    "\n",
    "uk_df = tweets_df.loc[tweets_df.user_location==\"United Kingdom\"]\n",
    "show_wordcloud(uk_df['text'], title = 'Prevalent words in tweets from UK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prevelant words in tweets - Canada\n",
    "\n",
    "ca_df = tweets_df.loc[tweets_df.user_location==\"Canada\"]\n",
    "show_wordcloud(ca_df['text'], title = 'Prevalent words in tweets from Canada')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hashtags Analysis\n",
    "\n",
    "def plot_features_distribution(features, title, df, isLog=False):\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.title(title)\n",
    "    for feature in features:\n",
    "        if(isLog):\n",
    "            sns.distplot(np.log1p(df[feature]),kde=True,hist=False, bins=120, label=feature)\n",
    "        else:\n",
    "            sns.distplot(df[feature],kde=True,hist=False, bins=120, label=feature)\n",
    "    plt.xlabel('')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the hashtags\n",
    "\n",
    "tweets_df['hashtags'] = tweets_df['hashtags'].replace(np.nan, \"['None']\", regex=True)\n",
    "tweets_df['hashtags'] = tweets_df['hashtags'].apply(lambda x: x.replace('\\\\N',''))\n",
    "tweets_df['hashtags_count'] = tweets_df['hashtags'].apply(lambda x: len(x.split(',')))\n",
    "plot_features_distribution(['hashtags_count'], 'Hashtags per tweet (all data)', tweets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df['hashtags_individual'] = tweets_df['hashtags'].apply(lambda x: x.split(','))\n",
    "from itertools import chain\n",
    "all_hashtags = set(chain.from_iterable(list(tweets_df['hashtags_individual'])))\n",
    "print(f\"There are totally: {len(all_hashtags)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df['hashtags_individual'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract country from location \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We load the country list from the additional database we added to this Notebook. We also create a country column in \n",
    "# the original dataset.\n",
    "\n",
    "country_df = pd.read_csv(\"Country_Codes.csv\", engine = 'python')\n",
    "country_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_df.columns = [\"country\", \"alpha2\", \"alpha3\", \"numeric\", \"iso\", 'Unnamed']\n",
    "country_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df['country'] = tweets_df['user_location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the tweets and countries databases\n",
    "#tweets_df = tweets_df.merge(country_df, on=\"country\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tw_add_df = tweets_df.groupby([\"country\", \"iso\", \"alpha3\"])['text'].count().reset_index()\n",
    "#tw_add_df.columns = [\"country\", \"iso\", \"alpha3\", \"tweets\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f\"tweets containing country information: {tw_add_df.tweets.sum()}\")\n",
    "#print(f\"tweets containing country information; distinct countries: {tw_add_df.country.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tweets/country (where country is specified)\n",
    "\n",
    "#plot_map(tw_add_df, \"Tweets per country (where country is specified)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract date & time features\n",
    "\n",
    "tweets_df['datedt'] = pd.to_datetime(tweets_df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df['year'] = tweets_df['datedt'].dt.year\n",
    "tweets_df['month'] = tweets_df['datedt'].dt.month\n",
    "tweets_df['day'] = tweets_df['datedt'].dt.day\n",
    "tweets_df['dayofweek'] = tweets_df['datedt'].dt.dayofweek\n",
    "tweets_df['hour'] = tweets_df['datedt'].dt.hour\n",
    "tweets_df['minute'] = tweets_df['datedt'].dt.minute\n",
    "tweets_df['dayofyear'] = tweets_df['datedt'].dt.dayofyear\n",
    "tweets_df['date_only'] = tweets_df['datedt'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time variation\n",
    "\n",
    "tweets_agg_df = tweets_df.groupby([\"date_only\"])[\"text\"].count().reset_index()\n",
    "tweets_agg_df.columns = [\"date_only\", \"count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_time_variation(df, x='date_only', y='count', hue=None, size=1, title=\"\", is_log=False):\n",
    "    f, ax = plt.subplots(1,1, figsize=(4*size,3*size))\n",
    "    g = sns.lineplot(x=x, y=y, hue=hue, data=df)\n",
    "    plt.xticks(rotation=90)\n",
    "    if hue:\n",
    "        plt.title(f'{y} grouped by {hue} | {title}')\n",
    "    else:\n",
    "        plt.title(f'{y} | {title}')\n",
    "    if(is_log):\n",
    "        ax.set(yscale=\"log\")\n",
    "    ax.grid(color='black', linestyle='dotted', linewidth=0.75)\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_time_variation(tweets_agg_df, title=\"Number of tweets / day of year\",size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_count(\"dayofweek\", \"tweets / day of week\", tweets_df, size=3, ordered=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_count(\"dayofyear\", \"tweets / day of year\", tweets_df, size=3, ordered=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_count(\"date_only\", \"tweets / date\", tweets_df,size=4, ordered=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_count(\"hour\", \"tweets / hour\", tweets_df,size=4, ordered=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_count(\"minute\", \"tweets / minute\", tweets_df,size=5, ordered=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment analysis\n",
    "\n",
    "# borrowed from https://www.kaggle.com/pashupatigupta/sentiments-transformer-vader-embedding-bert\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "def find_sentiment(post):\n",
    "    if sia.polarity_scores(post)[\"compound\"] > 0:\n",
    "        return \"Positive\"\n",
    "    elif sia.polarity_scores(post)[\"compound\"] < 0:\n",
    "        return \"Negative\"\n",
    "    else:\n",
    "        return \"Neutral\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sentiment(df, feature, title):\n",
    "    counts = df[feature].value_counts()\n",
    "    percent = counts/sum(counts)\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12, 5))\n",
    "\n",
    "    counts.plot(kind='bar', ax=ax1, color='green')\n",
    "    percent.plot(kind='bar', ax=ax2, color='blue')\n",
    "    ax1.set_ylabel(f'Counts : {title} sentiments', size=12)\n",
    "    ax2.set_ylabel(f'Percentage : {title} sentiments', size=12)\n",
    "    plt.suptitle(f\"Sentiment analysis: {title}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df['sentiment'] = tweets_df['text'].apply(lambda x: find_sentiment(x))\n",
    "plot_sentiment(tweets_df, 'sentiment', 'Text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prevelant words in Positive tweets\n",
    "\n",
    "show_wordcloud(tweets_df.loc[tweets_df['sentiment']=='Positive', 'text'], \n",
    "               title = 'Prevalent words in tweets (Positive sentiment)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prevelant words in Negative tweets\n",
    "\n",
    "show_wordcloud(tweets_df.loc[tweets_df['sentiment']=='Negative', 'text'], \n",
    "               title = 'Prevalent words in tweets (Negative sentiment)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prevelant words in neutral tweets\n",
    "\n",
    "show_wordcloud(tweets_df.loc[tweets_df['sentiment']=='Neutral', 'text'], \n",
    "               title = 'Prevalent words in tweets (Neutral sentiment)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tweets_df.to_csv('Tweets_Full_Set.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData]",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
